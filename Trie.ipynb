{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Trie class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "# Trie class\n",
    "class Trie:\n",
    "  # init Trie class\n",
    "  def __init__(self):\n",
    "    self.root = self.getNode()\n",
    "\n",
    "  def getNode(self):\n",
    "    return {\"isEndOfWord\": False, \"children\": {}}\n",
    "\n",
    "  def insertWord(self, word):\n",
    "    current = self.root\n",
    "    for ch in word:\n",
    "\n",
    "      # if current[\"children\"].has_key(ch):\n",
    "      if ch in current[\"children\"]:\n",
    "        node = current[\"children\"][ch]\n",
    "      else:\n",
    "        node = self.getNode()\n",
    "        current[\"children\"][ch] = node\n",
    "\n",
    "      current = node\n",
    "    current[\"isEndOfWord\"] = True\n",
    "\n",
    "  def searchWord(self, word):\n",
    "    current = self.root\n",
    "    for ch in word:\n",
    "      if ch not in current[\"children\"]:\n",
    "        return False\n",
    "      node = current[\"children\"][ch]\n",
    "\n",
    "      current = node\n",
    "    return current[\"isEndOfWord\"]\n",
    "\n",
    "  def searchWordPrefix(self, word):\n",
    "    current = self.root\n",
    "    for ch in word:\n",
    "      if ch not in current[\"children\"]:\n",
    "        return False\n",
    "      node = current[\"children\"][ch]\n",
    "\n",
    "      current = node\n",
    "    # return True if children contain keys and values\n",
    "    return bool(current[\"children\"])\n",
    "\n",
    "  def deleteWord(self, word):\n",
    "    self._delete(self.root, word, 0)\n",
    "\n",
    "  def _delete(self, current, word, index):\n",
    "    if(index == len(word)):\n",
    "      if not current[\"isEndOfWord\"]:\n",
    "        return False\n",
    "      current[\"isEndOfWord\"] = False\n",
    "      return len(current[\"children\"].keys()) == 0\n",
    "\n",
    "    ch = word[index]\n",
    "    # if not current[\"children\"].has_key(ch):\n",
    "    if ch not in current[\"children\"]:\n",
    "      return False\n",
    "    node = current[\"children\"][ch]\n",
    "\n",
    "    should_delete_current_node = self._delete(node, word, index + 1)\n",
    "\n",
    "    if should_delete_current_node:\n",
    "      current[\"children\"].pop(ch)\n",
    "      return len(current[\"children\"].keys()) == 0\n",
    "\n",
    "    return False\n",
    "\n",
    "  def save_to_pickle(self, file_name):\n",
    "    f = open(file_name + \".pkl\", \"wb\")\n",
    "    pickle.dump(self.root, f)\n",
    "    f.close()\n",
    "\n",
    "  def load_from_pickle(self, file_name):\n",
    "    f = open(file_name + \".pkl\", \"rb\")\n",
    "    self.root = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "  def save_to_json(self, file_name):\n",
    "    json_data = json.dumps(self.root)\n",
    "    f = open(file_name + \".json\", \"w\")\n",
    "    f.write(json_data)\n",
    "    f.close()\n",
    "\n",
    "  def load_from_json(self, file_name):\n",
    "    json_file = open(file_name + \".json\", \"r\")\n",
    "    self.root = json.load(json_file)\n",
    "    json_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Let start train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "model = Trie()\n",
    "input_file_path = \"data/sea.txt\"\n",
    "with open(input_file_path, \"r\") as f:\n",
    "  words = f.read().split(\"\\n\")\n",
    "print(\"Training start\")\n",
    "\n",
    "for word in words:\n",
    "  if not bool(word.strip()):\n",
    "    continue\n",
    "\n",
    "  model.insertWord(word)\n",
    "\n",
    "#model.save_to_pickle(\"train_data_v2\")\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lest test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.searchWord('')) # should False\n",
    "print(model.searchWord('គ្រុយ')) # should be True\n",
    "print(model.searchWord('គ្រុ')) # should be False\n",
    "#print(model.searchWordPrefix('គ្រុ')) # should be True\n",
    "#print(model.searchWordPrefix('សួ')) # should be False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let build model for seperated word from sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordSegmentation:\n",
    "  # init Trie class\n",
    "  def __init__(self, text):\n",
    "    self.text = text#.decode('utf-8')\n",
    "    self.model = Trie()\n",
    "    self.model.load_from_pickle(\"train_data_v2\")\n",
    "    # self.result = []\n",
    "    self.result_all = []\n",
    "    # self.leftover = []\n",
    "    self.startIndex = 0\n",
    "\n",
    "  def isNumber(self, ch):\n",
    "    # number letter\n",
    "    return ch in \"0123456789០១២៣៤៥៦៧៨៩\"\n",
    "\n",
    "  def parseNumber(self, index):\n",
    "    result = \"\"\n",
    "    while (index < len(self.text)):\n",
    "      ch = self.text[index]\n",
    "      ch = ch#.encode('utf-8')\n",
    "      if self.isNumber(ch):\n",
    "        result += self.text[index]\n",
    "        index += 1\n",
    "      else:\n",
    "        return result\n",
    "\n",
    "    return result\n",
    "  def isEnglish(self, ch):\n",
    "    return ch in \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "  def parseEnglish(self, index):\n",
    "    result = \"\"\n",
    "    while (index < len(self.text)):\n",
    "      ch = self.text[index]\n",
    "      ch = ch#.encode('utf-8')\n",
    "      if (self.isEnglish(ch) or self.isNumber(ch)):\n",
    "        result += ch;\n",
    "        index += 1\n",
    "      else:\n",
    "        return result\n",
    "    return result\n",
    "\n",
    "  def parseTrie(self, index):\n",
    "    word = ''\n",
    "    foundWord = ''\n",
    "\n",
    "    while (index < len(self.text)):\n",
    "      ch = self.text[index]\n",
    "      ch = ch#.encode('utf-8')\n",
    "      word += ch\n",
    "      if self.model.searchWordPrefix(word):\n",
    "        if self.model.searchWord(word):\n",
    "          foundWord = word\n",
    "      elif self.model.searchWord(word):\n",
    "        return word\n",
    "      else:\n",
    "        return foundWord;\n",
    "\n",
    "      index += 1\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "  def check_words(self):\n",
    "    while(self.startIndex < len(self.text)):\n",
    "      ch = self.text[self.startIndex]\n",
    "      ch = ch#.encode('utf-8')\n",
    "      word = ''\n",
    "\n",
    "      if self.isNumber(ch):\n",
    "        word = self.parseNumber(self.startIndex)#.encode('utf-8')\n",
    "      elif self.isEnglish(ch):\n",
    "        word = self.parseEnglish(self.startIndex)#.encode('utf-8')\n",
    "      else:\n",
    "        word = self.parseTrie(self.startIndex)\n",
    "\n",
    "      length = len(word)#.decode('utf-8'))\n",
    "      if length == 0:\n",
    "        self.result_all.append(ch)#.decode('utf-8'))\n",
    "        self.startIndex += 1\n",
    "        continue\n",
    "\n",
    "      result = {}\n",
    "      if self.model.searchWord(word) or self.isNumber(ch) or self.isEnglish(ch):\n",
    "        #self.result_all.append()\n",
    "        result[\"text\"] = word#.decode('utf-8')\n",
    "      else:\n",
    "        result[\"text\"] = word#.decode('utf-8')\n",
    "\n",
    "      self.result_all.append(result)\n",
    "      self.startIndex += length\n",
    "\n",
    "    # # write to file\n",
    "    # with open('result/segment_word.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    #   for word in self.result:\n",
    "    #     f.write(word + \"\\n\")\n",
    "    # with open('result/segment_not_word.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "    #   for word in self.leftover:\n",
    "    #     f.write(word + \"\\n\")\n",
    "\n",
    "  def show(self):\n",
    "    print('Text: ' + self.text)\n",
    "    print(self.result_all)\n",
    "    #print('After check : [' + ', '.join(self.result_all) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: កំពុងលុបការឃោសនារបស់ពួកជ្រុលនិយមលឿនជាងបច្ចុប្បន្ន បើមិនដូច្នេះទេ\n",
      "[{'text': 'កំពុង'}, {'text': 'លុប'}, {'text': 'ការឃោសនា'}, {'text': 'របស់'}, {'text': 'ពួក'}, {'text': 'ជ្រុល'}, {'text': 'និយម'}, {'text': 'លឿន'}, {'text': 'ជាង'}, {'text': 'បច្ចុប្បន្ន'}, ' ', {'text': 'បើមិន'}, 'ដ', 'ូ', {'text': 'ច្នេះ'}, 'ទ', 'េ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# kh_text = \"អ្នកចេះនិយាយភាសាខ្មែរទេ?\"\n",
    "# kh_text = \"ចំណេះ​ដឹង​វិទ្យាសាស្ត្រ​ជា​ចំណុច​គាំទ្រ​ដ៏​សំខាន់​មួយ​ក្នុង​ការ​អភិវឌ្ឍ​សេដ្ឋកិច្ច​សង្គម។ \"\n",
    "# kh_text = \"ដឹង​វិទ្យាសាស្ត្រ​ជា​ចំណុច​គាំទ្រ​ដ៏​សំខាន់​មួយ​ក្នុង​ការ​អភិវឌ្ឍ​សេដ្ឋកិច្ច​សង្គម។\"\n",
    "kh_text = \"កំពុងលុបការឃោសនារបស់ពួកជ្រុលនិយមលឿនជាងបច្ចុប្បន្ន បើមិនដូច្នេះទេ\"\n",
    "#kh_text = \"សហភាពអឺរ៉ុបបានផ្ដល់ពេល៣ខែឲ្\"\n",
    "#kh_text = \"ខាងក្រុមហ៊ុនរបស់យើងខ្ញុំត្រូវការជ្រើសរើសនិសិ្សតកម្ពុជាយើងដែលកំពុងរៀនផ្នែកពត័មានវិទ្យានិងផ្នែកទូរគមនាគមន៍\"\n",
    "\n",
    "word_segment = WordSegmentation(kh_text)\n",
    "word_segment.check_words()\n",
    "word_segment.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
